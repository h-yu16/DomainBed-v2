# DomainBed-v2

Official repo for CVPR 2024 paper "Rethinking the Evaluation Protocol of Domain Generalization" \[[arxiv](https://arxiv.org/pdf/2305.15253)\] \[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yu_Rethinking_the_Evaluation_Protocol_of_Domain_Generalization_CVPR_2024_paper.pdf)\].

This repo is built upon [DomainBed](https://github.com/facebookresearch/DomainBed) and [SWAD](https://github.com/khanrc/swad). 

## Revised evaluation protocol

To mitigate potential test data information leakage for fairer and more accurate comparison between various algorithms, in our paper we suggest running experiments of domain generalization under the revised evaluation protocol, i.e. **adopt self-supervised pretrained weights (MoCo-v2 pretrained ResNet-50 and MoCo-v3 pretrained ViT-B/16) and evaluate on multiple test domains**, which are supported in this repo. 

The pretrained weights involved in this repo are from:
- MoCo pretrained ResNet-50: From the official pytorch implementation of [MoCo](https://github.com/facebookresearch/moco/) ([Downloading link](https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v1_200ep/moco_v1_200ep_pretrain.pth.tar)). 

- **MoCo-v2 pretrained ResNet-50**: From the official pytorch implementation of [MoCo](https://github.com/facebookresearch/moco/) ([Downloading link](https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/moco_v2_200ep_pretrain.pth.tar)). 
- **MoCo-v3 pretrained ViT-B/16**: From the official pytorch implementation of [MoCo-v3](https://github.com/facebookresearch/moco-v3) ([Downloading link](https://dl.fbaipublicfiles.com/moco-v3/vit-b-300ep/vit-b-300ep.pth.tar)).

- SimCLR pretrained ResNet-50: From the pytorch implementation of [SimCLR](https://github.com/sthalles/SimCLR) ([Downloading link](https://drive.google.com/open?id=1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu)). The checkpoint is in the zip-compressed file. 

- SimCLR-v2 pretrained ResNet-50: From the official TensorFlow implementation of [SimCLR](https://github.com/google-research/simclr) and converted to pytorch weights with the help of a [converter](https://github.com/Separius/SimCLRv2-Pytorch). Here is the [downloading link](https://drive.google.com/file/d/1BCPleX4Ef1I7ecsW4pvz0skdB40lN3Mj/view?usp=sharing) that has already been converted and can be directly used. 

In the modified protocol, only MoCo-v2 pretrained ResNet-50 and MoCo-v3 pretrained ViT-B/16 are required, which are also marked in bold above. After downloading the pretrained weights, it could be placed in the directory `~/Pretrained_Weights`. 

For multiple test domains, arbitrary specification of training domains and test domains is allowed via the arguments of source and target. 

## Other modifications

Other main modifications compared with the original implementation of DomainBed and SWAD include:

- Data input: We employ txt files to store the file paths and labels of the dataset. Usually each txt file represents a domain. Here is [downloading link](https://drive.google.com/file/d/1gjzlmZmwgJsWkQt3xzSfPzgv4u3-zWV3/view?usp=sharing) to the txt files.

- Repeated experiments: In DomainBed, the number of trials for hyperparameter search is 20 for each of 3 random seeds in each setting. In our implementation, to reduce computational cost, we reduce the number of trials to 10 for one random seed of each setting, and directly use the searched hyperparameters for the other two random seeds instead of searching again. 

- Hyperparameter search space: We use a json file `pretrain.json` to store the hyperparameter search space. 

- Result collection: We write python scripts to generate Linux shell scripts to run experiments and collect results. Here we provide three python scripts:

    - `generate_scripts.py`: Generate scripts in the current directory to run experiments. Each generated script corresponds to hyperparameter search (10 trials) of a setting. This file could be placed in a directory where the scripts will be generated. 

    - `collect.py`: Collect experiment results and place the optimal hyperparameters in the corresponding directory.

    - `generate_scripts_seed.py`: Generate scripts in the current directory to run experiments. Each generated script corresponds to the other two random seeds of a setting. This file could be placed in a directory where optimal hyperparameters are put via `collect.py`.

The hyperparameter search space file `pretrain.json` needs to be copied into the directory of `generate_scripts.py`.

## Example

Here is an example shell script generated by `generate_scripts.py` (when placed in the directory `scripts_resnet50`):
```shell
gpu=1
min=1
max=10
seed=1
data_seed=1
for hpseed in `seq $min $max`
do
CUDA_VISIBLE_DEVICES=$gpu python -m domainbed.scripts.train \
--arch resnet50 --pretrain MoCo-v2 --algorithm CORAL \
--dataset PACS \
--source photo cartoon sketch --target art \
--seed $seed --data_seed $data_seed --hparams_seed $hpseed \
--hparams_rand_config scripts_resnet50/pretrain.json \
--result_name PACS_art_CORAL_MoCo-v2_resnet50 --output_dir train_output_resnet50
done
```

Here is an example shell script generated by `generate_scripts_seed.py` (when placed in the directory `scripts_resnet50_seed`):
```shell
gpu=1
min=2
max=3
seed=1
for dataseed in `seq $min $max`
do
CUDA_VISIBLE_DEVICES=$gpu python -m domainbed.scripts.train \
--arch resnet50 --pretrain MoCo-v2 --algorithm CORAL \
--dataset PACS \
--source photo cartoon sketch --target art \
--seed $seed --data_seed $dataseed \
--hparams_fixed_config scripts_resnet50_seed/PACS/art/CORAL_MoCo-v2.json \
--result_name PACS_art_CORAL_MoCo-v2_resnet50 --output_dir train_output_resnet50_seed
done
```

## Citation

If you find this repo useful for your research, please consider citing the paper.

```bibtex
@inproceedings{yu2024rethinking,
  title={Rethinking the evaluation protocol of domain generalization},
  author={Yu, Han and Zhang, Xingxuan and Xu, Renzhe and Liu, Jiashuo and He, Yue and Cui, Peng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21897--21908},
  year={2024}
}
```
